{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import heapq\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the text_mining function to compute: tokenization, stemming and removal of stopwords, numbers and punctuations of the input text. We used the nltk library for these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mining(synopsis):\n",
    "    tokens = nltk.word_tokenize(synopsis)                           #tokenization\n",
    "    tokens = [word for word in tokens if word.isalpha()]            #remove punctuations and numbers\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))        #remove stopwords\n",
    "    tokens = [word for word in tokens if not word.lower() in stop_words]       \n",
    "    tokens = [PorterStemmer().stem(word) for word in tokens]        #stemming\n",
    "    tokens = [str(hash(word)) for word in tokens]       #consider the hash code of the words will be useful for the next queries\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(text):\n",
    "    for word in set(text):                                          #create the vocabuary according to the synopsis \n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description1, description2 = {}, {}\n",
    "vocabulary = []\n",
    "len_anime = 19128\n",
    "for j in range(0,383):\n",
    "    for i in range((50*j)+1, (50*(j+1))+1):\n",
    "        if i == 7242 or i ==15009:\n",
    "            continue\n",
    "        if i == 19131:\n",
    "            break\n",
    "        #doc = \"\".join(\"documento \"+str(i))\n",
    "        tsv_file = open(\"pages_tsv/pages_tsv/page_\" + str(j+1) + \"/anime_\" + str(i)+ \".tsv\", 'r', encoding=\"utf-8\")\n",
    "        anime = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        anime = anime.__next__()\n",
    "        title = anime['animeTitle']\n",
    "        synopsis = anime['animeDescription']\n",
    "        description2[i] = [synopsis, title] \n",
    "        synopsis = text_mining(synopsis)\n",
    "        vocab(synopsis)\n",
    "        description1[i] = synopsis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(vocabulary))                    #create the vocabulatory with non repetitions of words\n",
    "file = open(\"vocabulary.txt\", \"w\", encoding = \"utf-8\")\n",
    "for word in vocabulary:\n",
    "    file.write(str(hash(word)) +\"\\n\")                 #create the file .txt that maps each word to a term_id using tha hash\n",
    "file.close()                                          #function of python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "for term_id in vocabulary:\n",
    "    for i in description1:\n",
    "        if term_id in description1[i]:\n",
    "            if term_id not in inverted_index:\n",
    "                inverted_index[term_id] =  [i]\n",
    "            else:\n",
    "                inverted_index[term_id] = inverted_index[term_id] + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_index.json\", \"w\", encoding=\"utf-8\") as file: \n",
    "    json.dump(dict(zip(inverted_index.keys(), map(list, inverted_index.values()))), file, indent = 4)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_index.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    inverted_index = json.load(file) \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_word(query):\n",
    "    d = []\n",
    "    query = set(text_mining(query))\n",
    "    for word in query:\n",
    "        if word in vocabulary:\n",
    "            d.append(inverted_index[word])\n",
    "        else:\n",
    "            return set()\n",
    "    if len(d)==1:\n",
    "        return d[0]\n",
    "    else:\n",
    "        for i in range(len(d)-1):\n",
    "            intersection = set(d[i]).intersection(set(d[i+1]))\n",
    "        return  intersection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "with open(\"anime_links.txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file:\n",
    "        url.append(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Dragon Ball Kai</td>\n",
       "      <td>Five years after the events of Dragon Ball, ma...</td>\n",
       "      <td>https://myanimelist.net/anime/6033/Dragon_Ball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>Five years after winning the World Martial Art...</td>\n",
       "      <td>https://myanimelist.net/anime/813/Dragon_Ball_Z\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             animeTitle  \\\n",
       "401                            Dragon Ball Super: Broly   \n",
       "1035                                    Dragon Ball Kai   \n",
       "365                                       Dragon Ball Z   \n",
       "1469  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "\n",
       "                                       animeDescription  \\\n",
       "401   Forty-one years ago on Planet Vegeta, home of ...   \n",
       "1035  Five years after the events of Dragon Ball, ma...   \n",
       "365   Five years after winning the World Martial Art...   \n",
       "1469  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "\n",
       "                                                    Url  \n",
       "401   https://myanimelist.net/anime/36946/Dragon_Bal...  \n",
       "1035  https://myanimelist.net/anime/6033/Dragon_Ball...  \n",
       "365   https://myanimelist.net/anime/813/Dragon_Ball_Z\\n  \n",
       "1469  https://myanimelist.net/anime/986/Dragon_Ball_...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"saiyan race\"\n",
    "result = pd.DataFrame(columns=['animeTitle', 'animeDescription', 'Url'])\n",
    "set_result = search_word(query)\n",
    "for i in set_result:\n",
    "    result.loc[i, \"animeDescription\"] = description2[i][0]\n",
    "    result.loc[i, \"animeTitle\"] = description2[i][1]\n",
    "    result.loc[i, \"Url\"] = url[i-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_term = {}\n",
    "inverted_doc = {}\n",
    "for term_id in vocabulary:\n",
    "    for i in description1:\n",
    "        if term_id in description1[i]:\n",
    "            tf = (description1[i].count(term_id)) / len(description1[i])\n",
    "            idf = np.log10(len_anime/(len(inverted_index[term_id])))\n",
    "            tfidf = tf * idf\n",
    "            if term_id not in inverted_term:\n",
    "                inverted_term[term_id] =  [[i, tfidf]]\n",
    "            else:\n",
    "                inverted_term[term_id] = inverted_term[term_id] + [[i, tfidf]]\n",
    "            if i not in inverted_doc:\n",
    "                inverted_doc[i] = tfidf\n",
    "            else:\n",
    "                inverted_doc[i] = inverted_doc[i] + tfidf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_term.json\", \"w\", encoding=\"utf-8\") as file: \n",
    "    json.dump(inverted_term, file, ensure_ascii=False)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_doc.json\", \"w\", encoding=\"utf-8\") as file: \n",
    "    json.dump(inverted_doc, file, ensure_ascii=False)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_term.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    inverted_term = json.load(file) \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inverted_doc.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    inverted_doc = json.load(file) \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similarity(query):\n",
    "    documents = search_word(query)\n",
    "    query = set(text_mining(query))\n",
    "    heap = []\n",
    "    heapq.heapify(heap)\n",
    "    result = {}\n",
    "\n",
    "    numeratore = {}\n",
    "    for word in query:\n",
    "        for i in inverted_term[word]:\n",
    "            if i[0] in documents:\n",
    "                if i[0] not in numeratore:\n",
    "                    numeratore[i[0]] = i[1]\n",
    "                else:\n",
    "                    numeratore[i[0]] = numeratore[i[0]]+ i[1]\n",
    "    count = 0\n",
    "    for elem in numeratore:\n",
    "        count += numeratore[elem]\n",
    "        \n",
    "    for document in documents:\n",
    "        cos_sim = numeratore[document]/(np.sqrt(inverted_doc[str(document)]) * np.sqrt(count))\n",
    "        result[document] = cos_sim\n",
    "        heapq.heappush(heap, cos_sim)\n",
    "    return result, heap\n",
    "              \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_anime(query, k):\n",
    "    res, heap = search_similarity(query)\n",
    "    heap_k = heapq.nlargest(k, heap)\n",
    "    result = []\n",
    "    for i in range(len(heap_k)):\n",
    "        pos = list(res.values()).index(heap_k[i])\n",
    "        result.append(list(res)[pos])\n",
    "    return result, res     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{401: 0.08140734173914635, 1035: 0.05119910412232713, 365: 0.060830150659738194, 1469: 0.22620464338614163}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "      <td>0.226205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "      <td>0.0814073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>Five years after winning the World Martial Art...</td>\n",
       "      <td>https://myanimelist.net/anime/813/Dragon_Ball_Z\\n</td>\n",
       "      <td>0.0608302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             animeTitle  \\\n",
       "1469  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "401                            Dragon Ball Super: Broly   \n",
       "365                                       Dragon Ball Z   \n",
       "\n",
       "                                       animeDescription  \\\n",
       "1469  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "401   Forty-one years ago on Planet Vegeta, home of ...   \n",
       "365   Five years after winning the World Martial Art...   \n",
       "\n",
       "                                                    Url Similarity  \n",
       "1469  https://myanimelist.net/anime/986/Dragon_Ball_...   0.226205  \n",
       "401   https://myanimelist.net/anime/36946/Dragon_Bal...  0.0814073  \n",
       "365   https://myanimelist.net/anime/813/Dragon_Ball_Z\\n  0.0608302  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"saiyan race\"\n",
    "k = 3\n",
    "data, dictionary = top_k_anime(query, k)\n",
    "print(dictionary)\n",
    "result2 = pd.DataFrame(columns=['animeTitle', 'animeDescription', 'Url', 'Similarity'])\n",
    "for i in data:\n",
    "    result2.loc[i, \"animeDescription\"] = description2[i][0]\n",
    "    result2.loc[i, \"animeTitle\"] = description2[i][1]\n",
    "    result2.loc[i, \"Url\"] = url[i-1]\n",
    "    result2.loc[i, \"Similarity\"] = dictionary[i]\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
