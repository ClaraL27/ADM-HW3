{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the text_mining function to compute: tokenization, stemming and removal of stopwords, numbers and punctuations of the input text. We used the nltk library for these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mining(synopsis):\n",
    "    tokens = nltk.word_tokenize(synopsis)                           #tokenization\n",
    "    tokens = [word for word in tokens if word.isalpha()]            #remove punctuations and numbers\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))        #remove stopwords\n",
    "    tokens = [word for word in tokens if not word.lower() in stop_words]       \n",
    "    tokens = [PorterStemmer().stem(word) for word in tokens]        #stemming\n",
    "    tokens = [str(hash(word)) for word in tokens]       #consider the hash code of the words will be useful for the next queries\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(text):\n",
    "    for word in set(text):                                          #create the vocabuary according to the synopsis \n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description1, description2 = {}, {}\n",
    "vocabulary = []\n",
    "len_anime = 19128\n",
    "for j in range(0,383):\n",
    "    for i in range((50*j)+1, (50*(j+1))+1):\n",
    "        if i == 7242 or i ==15009:\n",
    "            continue\n",
    "        if i == 19131:\n",
    "            break\n",
    "        doc = \"\".join(\"documento \"+str(i))\n",
    "        tsv_file = open(\"pages_tsv/pages_tsv/page_\" + str(j+1) + \"/anime_\" + str(i)+ \".tsv\", 'r', encoding=\"utf-8\")\n",
    "        anime = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        anime = anime.__next__()\n",
    "        title = anime['animeTitle']\n",
    "        synopsis = anime['animeDescription']\n",
    "        description2[doc] = [synopsis, title] \n",
    "        synopsis = text_mining(synopsis)\n",
    "        vocab(synopsis)\n",
    "        description1[doc] = synopsis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(set(vocabulary))                    #create the vocabulatory with non repetitions of words\n",
    "file = open(\"vocabulary.txt\", \"w\", encoding = \"utf-8\")\n",
    "for word in vocabulary:\n",
    "    file.write(str(hash(word)) +\"\\n\")                 #create the file .txt that maps each word to a term_id using tha hash\n",
    "file.close()                                          #function of python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "for term_id in vocabulary:\n",
    "    for i in description1:\n",
    "        if term_id in description1[i]:\n",
    "            if term_id not in inverted_index:\n",
    "                inverted_index[term_id] =  [i]\n",
    "            else:\n",
    "                inverted_index[term_id] = inverted_index[term_id] + [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_word(query):\n",
    "    d = []\n",
    "    query = set(text_mining(query))\n",
    "    for word in query:\n",
    "        if word in vocabulary:\n",
    "            d.append(inverted_index[word])\n",
    "        else:\n",
    "            return set()\n",
    "    if len(d)==1:\n",
    "        return d[0]\n",
    "    else:\n",
    "        for i in range(len(d)-1):\n",
    "            intersection = set(d[i]).intersection(set(d[i+1]))\n",
    "        return  intersection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "with open(\"anime_links.txt\", \"r\", encoding = \"utf-8\") as file:\n",
    "    for line in file:\n",
    "        url.append(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>documento 401</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documento 365</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>Five years after winning the World Martial Art...</td>\n",
       "      <td>https://myanimelist.net/anime/813/Dragon_Ball_Z\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documento 1469</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documento 1035</th>\n",
       "      <td>Dragon Ball Kai</td>\n",
       "      <td>Five years after the events of Dragon Ball, ma...</td>\n",
       "      <td>https://myanimelist.net/anime/6033/Dragon_Ball...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       animeTitle  \\\n",
       "documento 401                            Dragon Ball Super: Broly   \n",
       "documento 365                                       Dragon Ball Z   \n",
       "documento 1469  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "documento 1035                                    Dragon Ball Kai   \n",
       "\n",
       "                                                 animeDescription  \\\n",
       "documento 401   Forty-one years ago on Planet Vegeta, home of ...   \n",
       "documento 365   Five years after winning the World Martial Art...   \n",
       "documento 1469  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "documento 1035  Five years after the events of Dragon Ball, ma...   \n",
       "\n",
       "                                                              Url  \n",
       "documento 401   https://myanimelist.net/anime/36946/Dragon_Bal...  \n",
       "documento 365   https://myanimelist.net/anime/813/Dragon_Ball_Z\\n  \n",
       "documento 1469  https://myanimelist.net/anime/986/Dragon_Ball_...  \n",
       "documento 1035  https://myanimelist.net/anime/6033/Dragon_Ball...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"saiyan race\"\n",
    "result = pd.DataFrame(columns=['animeTitle', 'animeDescription', 'Url'])\n",
    "set_result = search_word(query)\n",
    "for i in set_result:\n",
    "    result.loc[i, \"animeDescription\"] = description2[i][0]\n",
    "    result.loc[i, \"animeTitle\"] = description2[i][1]\n",
    "    num = i.split(\" \")\n",
    "    result.loc[i, \"Url\"] = url[int(num[1])-1]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted = {}\n",
    "for term_id in vocabulary:\n",
    "    for i in description1:\n",
    "        if term_id in description1[i]:\n",
    "            tf = (description1[i].count(term_id)) / len(description1[i])\n",
    "            idf = np.log10(len_anime/(len(inverted_index[term_id])))\n",
    "            tfidf = tf * idf\n",
    "            if term_id not in inverted:\n",
    "                inverted[term_id] =  [i, tfidf]\n",
    "            else:\n",
    "                inverted[term_id] = inverted[term_id] + [i, tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_array(query):\n",
    "    query = text_mining(query)\n",
    "    query_array = np.zeros(len(vocabulary))\n",
    "    for i in range(len(vocabulary)):\n",
    "        if vocabulary[i] in query:\n",
    "            query_array[i] = 1\n",
    "    return query_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to create the anime array\n",
    "anime_array = np.zeros([len_anime, len(vocabulary)])\n",
    "for i in range(len(vocabulary)):\n",
    "    for word in inverted:\n",
    "        tfidf = inverted[word][1]\n",
    "        doc = (inverted[word][0]).split(\" \")\n",
    "        num_doc = int(doc[1])-1\n",
    "        anime_array[num_doc][i] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similarity(query):\n",
    "    result = {}\n",
    "    documents = search_word(query)\n",
    "    query_array = create_query_array(query)\n",
    "    heap = []\n",
    "    heapq.heapify(heap)\n",
    "            \n",
    "    for document in documents:\n",
    "        docs = document.split(\" \")\n",
    "        num_document = int(docs[1])-1\n",
    "        anime = anime_array[num_document]\n",
    "        cos_sim = np.dot(query_array, anime)/(norm(anime)*norm(query_array))\n",
    "        result[document] = cos_sim\n",
    "        heapq.heappush(heap, cos_sim)\n",
    "    return result, heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_anime(query, k):\n",
    "    res, heap = search_similarity(query)\n",
    "    heap_k = heapq.nlargest(k, heap)\n",
    "    result = []\n",
    "    for i in range(len(heap_k)):\n",
    "        pos = list(res.values()).index(heap_k[i])\n",
    "        result.append(list(res)[pos])\n",
    "    return result, res     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documento 401': 0.0076008823616397795, 'documento 365': 0.007600882361639766, 'documento 1469': 0.0076008823616397735, 'documento 1035': 0.007600882361639773}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeTitle</th>\n",
       "      <th>animeDescription</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>documento 401</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>Forty-one years ago on Planet Vegeta, home of ...</td>\n",
       "      <td>https://myanimelist.net/anime/36946/Dragon_Bal...</td>\n",
       "      <td>0.00760088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documento 1469</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>Bardock, Son Goku's father, is a low-ranking S...</td>\n",
       "      <td>https://myanimelist.net/anime/986/Dragon_Ball_...</td>\n",
       "      <td>0.00760088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documento 1035</th>\n",
       "      <td>Dragon Ball Kai</td>\n",
       "      <td>Five years after the events of Dragon Ball, ma...</td>\n",
       "      <td>https://myanimelist.net/anime/6033/Dragon_Ball...</td>\n",
       "      <td>0.00760088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       animeTitle  \\\n",
       "documento 401                            Dragon Ball Super: Broly   \n",
       "documento 1469  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "documento 1035                                    Dragon Ball Kai   \n",
       "\n",
       "                                                 animeDescription  \\\n",
       "documento 401   Forty-one years ago on Planet Vegeta, home of ...   \n",
       "documento 1469  Bardock, Son Goku's father, is a low-ranking S...   \n",
       "documento 1035  Five years after the events of Dragon Ball, ma...   \n",
       "\n",
       "                                                              Url  Similarity  \n",
       "documento 401   https://myanimelist.net/anime/36946/Dragon_Bal...  0.00760088  \n",
       "documento 1469  https://myanimelist.net/anime/986/Dragon_Ball_...  0.00760088  \n",
       "documento 1035  https://myanimelist.net/anime/6033/Dragon_Ball...  0.00760088  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"saiyan race\"\n",
    "k = 3\n",
    "data, dictionary = top_k_anime(query, k)\n",
    "print(dictionary)\n",
    "result2 = pd.DataFrame(columns=['animeTitle', 'animeDescription', 'Url', 'Similarity'])\n",
    "for i in data:\n",
    "    result2.loc[i, \"animeDescription\"] = description2[i][0]\n",
    "    result2.loc[i, \"animeTitle\"] = description2[i][1]\n",
    "    num = i.split(\" \")\n",
    "    result2.loc[i, \"Url\"] = url[int(num[1])-1]\n",
    "    result2.loc[i, \"Similarity\"] = dictionary[i]\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
