{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from functions import *\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data ollection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Get the list of animes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**THE CELL BELOW MUST BE RUNNED JUST ONE TIME, COMMENT IT**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# get_link('https://myanimelist.net/topanime.php?limit=', 'anime_links.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Crawl animes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# how many urls has the text file\n",
    "with open('anime_links.txt', 'r', encoding='utf-8') as file:\n",
    "    urls = list(file.read().splitlines())\n",
    "    len_list = len(urls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**THE CELL BELOW MUST BE RUNNED JUST ONE TIME, COMMENT IT**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# os.mkdir('pages')\n",
    "# for i in range(len_list//50 + 1):\n",
    "#     os.mkdir(f'pages/page_{i + 1}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**THE CELL BELOW MUST BE RUNNED JUST ONE TIME, COMMENT IT**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# change the start_ind value if the process stops\n",
    "# and the crawling will continue from that index\n",
    "# change stop_ind value to recover only the pages\n",
    "# from start_ind to stop_ind\n",
    "\n",
    "# start_ind = 0\n",
    "# stop_ind = len_list\n",
    "# crawl_html(start_ind)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Parse downloaded pages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`article_7242.html` and `article_15009.html` are missing, because the anime url doesn't exist:<br>\n",
    "https://myanimelist.net/anime/2644/Doraemon__Treasure_of_the_Shinugumi_Mountain<br>\n",
    "https://myanimelist.net/anime/43247/Bing_Di_Lian"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**THE CELL BELOW MUST BE RUNNED JUST ONE TIME, COMMENT IT**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# os.mkdir('pages_tsv')\n",
    "# for i in range(len_list//50 + 1):\n",
    "#     os.mkdir(f'pages_tsv/page_{i + 1}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nfor i in tqdm(range(len_list)):\\n    # the files with the indexes below do not exist\\n    if i == 7241 or i == 15008:\\n        continue\\n    page = i//50 + 1\\n    with open(f'pages/page_{page}/article_{i+1}.html', 'r', encoding='utf-8') as file:\\n        soup = BeautifulSoup(file, 'html.parser')\\n        with open(f'pages_tsv/page_{page}/anime_{i+1}.tsv', 'w', encoding='utf-8') as tsv_file:\\n            tsv = csv.writer(tsv_file, delimiter='\\t')\\n            tsv.writerow(['animeTitle', 'animeType', 'animeNumEpisode', 'releaseDate', 'endDate', 'animeNumMembers', 'animeScore', 'animeUsers', 'animeRank', 'animePopularity', 'animeDescription', 'animeRelated', 'animeCharacters', 'animeVoices', 'animeStaff'])\\n            tsv.writerow([get_title(soup), get_type(soup), get_num_ep(soup), get_dates(soup)[0], get_dates(soup)[1], get_memb(soup), get_score(soup), get_users(soup), get_rank(soup), get_pop(soup), get_descr(soup), get_rel_an(soup), get_char(soup), get_voices(soup), get_staff(soup)])\\n\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in tqdm(range(len_list)):\n",
    "    # the files with the indexes below do not exist\n",
    "    if i == 7241 or i == 15008:\n",
    "        continue\n",
    "    page = i//50 + 1\n",
    "    with open(f'pages/page_{page}/article_{i+1}.html', 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        with open(f'pages_tsv/page_{page}/anime_{i+1}.tsv', 'w', encoding='utf-8') as tsv_file:\n",
    "            tsv = csv.writer(tsv_file, delimiter='\\t')\n",
    "            tsv.writerow(['animeTitle', 'animeType', 'animeNumEpisode', 'releaseDate', 'endDate', 'animeNumMembers', 'animeScore', 'animeUsers', 'animeRank', 'animePopularity', 'animeDescription', 'animeRelated', 'animeCharacters', 'animeVoices', 'animeStaff'])\n",
    "            tsv.writerow([get_title(soup), get_type(soup), get_num_ep(soup), get_dates(soup)[0], get_dates(soup)[1], get_memb(soup), get_score(soup), get_users(soup), get_rank(soup), get_pop(soup), get_descr(soup), get_rel_an(soup), get_char(soup), get_voices(soup), get_staff(soup)])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Search Engine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. Conjunctive query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Clara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Clara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 383/383 [00:18<00:00, 20.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# download all the nltk files needed\n",
    "download()\n",
    "\n",
    "# creates the vocabulary of every word in the Synopsis of every anime\n",
    "# and stores it in a json file\n",
    "create_vocab()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1) Create your index!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:20<00:00, 18.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# creates the inverted index dictionary and stores it in a json file\n",
    "# invertedIndex()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2) Execute the query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below is used to open the vocabulary's terms, the inverted_index and the anime_links and to store them in global variables to use in other functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# opening the vocabulary\n",
    "voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "vocabulary = json.load(voc_json)\n",
    "voc_json.close()\n",
    "\n",
    "# opening the inverted_index\n",
    "inv_ind_json = open('inverted_index.json', 'r', encoding='utf-8')\n",
    "inverted_index = json.load(inv_ind_json)\n",
    "inv_ind_json.close()\n",
    "\n",
    "# opening the anime_links\n",
    "list_url_txt = open('anime_links.txt', 'r', encoding='utf-8')\n",
    "list_url = list_url_txt.read().splitlines()\n",
    "list_url_txt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saiyan race\n"
     ]
    }
   ],
   "source": [
    "# taking in input the query\n",
    "query = input(\"Insert the query: \")\n",
    "assert len(query) > 0, \"The query is empty!!\"\n",
    "# stemming the query\n",
    "query_stemmed = text_mining(query)\n",
    "print(query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# creating index query dictionary\n",
    "query_dict = dict()\n",
    "for word in query_stemmed:\n",
    "    if word in vocabulary.keys():\n",
    "        query_dict[vocabulary[word]] = inverted_index[str(vocabulary[word])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents found with the query = {'document_401', 'document_1035', 'document_365', 'document_1469'}\n"
     ]
    }
   ],
   "source": [
    "# saving the inverted_index of the query\n",
    "query_index = list(query_dict.keys())\n",
    "\n",
    "\n",
    "# searching for the documents requested from the query\n",
    "doc_list = set(query_dict[query_index[0]])\n",
    "for query_word in query_index[1:]:\n",
    "    doc_list.intersection_update(query_dict[query_word])\n",
    "\n",
    "print(\"List of documents found with the query =\", doc_list)\n",
    "\n",
    "# creating a pandas dataframe for the final result\n",
    "doc_df = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\"])\n",
    "for doc in doc_list:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x28ca99b1130>",
      "text/html": "<style type=\"text/css\">\n#T_88310_ th {\n  text-align: center;\n}\n#T_88310_row0_col0, #T_88310_row0_col1, #T_88310_row0_col2, #T_88310_row1_col0, #T_88310_row1_col1, #T_88310_row1_col2, #T_88310_row2_col0, #T_88310_row2_col1, #T_88310_row2_col2, #T_88310_row3_col0, #T_88310_row3_col1, #T_88310_row3_col2 {\n  text-align: center;\n}\n</style>\n<table id=\"T_88310_\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th class=\"col_heading level0 col0\" >animeTitle</th>\n      <th class=\"col_heading level0 col1\" >animeDescription</th>\n      <th class=\"col_heading level0 col2\" >Url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_88310_level0_row0\" class=\"row_heading level0 row0\" >document_401</th>\n      <td id=\"T_88310_row0_col0\" class=\"data row0 col0\" >Dragon Ball Super: Broly</td>\n      <td id=\"T_88310_row0_col1\" class=\"data row0 col1\" >Forty-one years ago on Planet Vegeta, home of the infamous Saiyan warrior race, King Vegeta noticed a baby named Broly whose latent power exceeded that of his own son. Believing that Broly's power would one day surpass that of his child, Vegeta, the king sends Broly to the desolate planet Vampa. Broly's father Paragus follows after him, intent on rescuing his son. However, his ship gets damaged, causing the two to spend years trapped on the barren world, unaware of the salvation that would one day come from an unlikely ally.\n\n\nYears later on Earth, Gokuu Son and Prince Vegeta—believed to be the last survivors of the Saiyan race—are busy training on a remote island. But their sparring is interrupted when the appearance of their old enemy Frieza drives them to search for the last of the wish-granting Dragon Balls on a frozen continent. Once there, Frieza shows off his new allies: Paragus and the now extremely powerful Broly. A legendary battle that shakes the foundation of the world ensues as Gokuu and Vegeta face off against Broly, a warrior without equal whose rage is just waiting to be unleashed.\n\n\n[Written by MAL Rewrite]</td>\n      <td id=\"T_88310_row0_col2\" class=\"data row0 col2\" ><a href=\"https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly\">https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly</a></td>\n    </tr>\n    <tr>\n      <th id=\"T_88310_level0_row1\" class=\"row_heading level0 row1\" >document_1035</th>\n      <td id=\"T_88310_row1_col0\" class=\"data row1 col0\" >Dragon Ball Kai</td>\n      <td id=\"T_88310_row1_col1\" class=\"data row1 col1\" >Five years after the events of Dragon Ball, martial arts expert Gokuu is now a grown man married to his wife Chi-Chi, with a four-year old son named Gohan. While attending a reunion on Turtle Island with his old friends Master Roshi, Krillin, Bulma and others, the festivities are interrupted when a humanoid alien named Raditz not only reveals the truth behind Gokuu's past, but kidnaps Gohan as well.\n\n\nWith Raditz displaying power beyond anything Gokuu has seen before, he is forced to team up with his old nemesis, Piccolo, in order to rescue his son. But when Gokuu and Piccolo reveal the secret of the seven mystical wish-granting Dragon Balls to Raditz, he informs the duo that there is more of his race, the Saiyans, and they won’t pass up an opportunity to seize the power of the Dragon Balls for themselves.\n\n\nThese events begin the saga of Dragon Ball Kai, a story that finds Gokuu and his friends and family constantly defending the galaxy from increasingly more powerful threats. Bizarre, comical, heartwarming and threatening characters come together in a series of battles that push the powers and abilities of Gokuu and his friends beyond anything they have ever experienced.</td>\n      <td id=\"T_88310_row1_col2\" class=\"data row1 col2\" ><a href=\"https://myanimelist.net/anime/6033/Dragon_Ball_Kai\">https://myanimelist.net/anime/6033/Dragon_Ball_Kai</a></td>\n    </tr>\n    <tr>\n      <th id=\"T_88310_level0_row2\" class=\"row_heading level0 row2\" >document_365</th>\n      <td id=\"T_88310_row2_col0\" class=\"data row2 col0\" >Dragon Ball Z</td>\n      <td id=\"T_88310_row2_col1\" class=\"data row2 col1\" >Five years after winning the World Martial Arts tournament, Gokuu is now living a peaceful life with his wife and son. This changes, however, with the arrival of a mysterious enemy named Raditz who presents himself as Gokuu's long-lost brother. He reveals that Gokuu is a warrior from the once powerful but now virtually extinct Saiyan race, whose homeworld was completely annihilated. When he was sent to Earth as a baby, Gokuu's sole purpose was to conquer and destroy the planet; but after suffering amnesia from a head injury, his violent and savage nature changed, and instead was raised as a kind and well-mannered boy, now fighting to protect others.\n\n\nWith his failed attempt at forcibly recruiting Gokuu as an ally, Raditz warns Gokuu's friends of a new threat that's rapidly approaching Earth—one that could plunge Earth into an intergalactic conflict and cause the heavens themselves to shake. A war will be fought over the seven mystical dragon balls, and only the strongest will survive in Dragon Ball Z.\n\n\n[Written by MAL Rewrite]</td>\n      <td id=\"T_88310_row2_col2\" class=\"data row2 col2\" ><a href=\"https://myanimelist.net/anime/813/Dragon_Ball_Z\">https://myanimelist.net/anime/813/Dragon_Ball_Z</a></td>\n    </tr>\n    <tr>\n      <th id=\"T_88310_level0_row3\" class=\"row_heading level0 row3\" >document_1469</th>\n      <td id=\"T_88310_row3_col0\" class=\"data row3 col0\" >Dragon Ball Z Special 1: Tatta Hitori no Saishuu Kessen</td>\n      <td id=\"T_88310_row3_col1\" class=\"data row3 col1\" >Bardock, Son Goku's father, is a low-ranking Saiyan soldier who was given the power to see into the future by the last remaining alien on a planet he just destroyed. He witnesses the destruction of his race and must now do his best to stop Frieza's impending massacre.\n\n\n(Source: ANN)</td>\n      <td id=\"T_88310_row3_col2\" class=\"data row3 col2\" ><a href=\"https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen\">https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen</a></td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_d = dict(selector=\"th\",\n",
    "             props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_d]).format({'Url': make_clickable})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Conjunctive query & Ranking score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.1) Inverted index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create two dictionaries:\n",
    "- inverted_term such that for each word we have the list of documents in which it is contained in, and the relative tfIdf score.\n",
    "- inverte_doc such that for each document we have the sum of the squares of the tfidf, we will use this dictonary in the execute query.\n",
    "\n",
    "We compute the tf-idf as $tf*idf$:\n",
    "- $tf=\\frac{n_i}{|d|}$, n is the number of occurences of the i-th word in the document and |d| is the number of words in the document\n",
    "- $idf=log_{10}\\left(\\frac{N}{n_d}\\right)$, N is the total number of documents and $n_d$ is the number of documents contaning the word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creates the inverted_index_tfidf and inverted_doc dictionaries and stores them in a json file\n",
    "invertedIndex_tfidf(vocabulary, inverted_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2.2) Execute the query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cell below is used to open the inverted_index_tfidf and the inverted_doc and to store them in global variables to use in other functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# opening the inverted_index\n",
    "inv_ind_tfidf_json = open('inverted_index_tfidf.json', 'r', encoding='utf-8')\n",
    "inverted_index_tfidf = json.load(inv_ind_tfidf_json)\n",
    "inv_ind_tfidf_json.close()\n",
    "\n",
    "# opening the anime_links\n",
    "inv_doc_json = open('inverted_doc.json', 'r', encoding='utf-8')\n",
    "inverted_doc = json.load(inv_doc_json)\n",
    "inv_doc_json.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given a query we get the set of documents containing all the words in the query and sort them according to their similarity to the query\n",
    "\n",
    "- First we consider only the documents that contain all the words in the query.\n",
    "\n",
    "- We create a dictionary called numerator such that for each document we have the tf-idf sum of the words in the query in reference to the document.\n",
    "\n",
    "- We compute the cosine similarity for each document as $ cos(\\theta) = \\frac{(\\vec{q} \\cdot \\vec{d})}{(|{\\vec{q}}| \\cdot |{\\vec{d}}|)}$ where:\n",
    "<p> $(\\vec{q} \\cdot \\vec{d})$ is the intersection of the document and the query vectors: we used the numerator dictonary argument for each document as intersection;<p>\n",
    "<p> $|{\\vec{q}}| \\cdot |{\\vec{d}}|$  are the norms of the document and query vectors . We compute $|{\\vec{q}}|$ as the square root of the length of the query (because the query vector has only components equal to 1 corresponding to the query words). We compute $|{\\vec{d}}|$ as the square root of the sum of the squares of the tf-idf of all words in the document (so we use the inverted_doc dictonary to compute the document norm)<p>\n",
    "\n",
    "- Then we create the result dictonary to store for each document the corresponding cosine similarity to the query."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taking in input the query\n",
    "query_2 = input(\"Insert the query: \")\n",
    "k = int(input(\"Insert k: \"))\n",
    "assert len(query_2) > 0, \"The query is empty!!\"\n",
    "assert isinstance(k, int), \"k should be an integer!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query_2)\n",
    "print(\"Query:\", query_2)\n",
    "print('k:', k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k, inverted_index, inverted_index_tfidf, inverted_doc, vocabulary)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "                props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To check that we were computing the cosine similarity in the right way, we did some tests considering the description of some documents as a query.\n",
    "<p>In the first test we used as a query the description of document 401 and the cosine similarity is 0.65, it is a high similarity value, but the value should have been around 1 (having used the document description itself). This does not happen because the description of the 401 document is very long (the number of words is high) and therefore the cosine similarity is less reliable. <p>\n",
    "<p>In the second test instead we used the description of document 203 which has only 7 words and in this case the cosine similarity is 0.96.<p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### FIRST TEST\n",
    "Using all anime description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taking in input the query\n",
    "query_2 = input(\"Insert the query: \")\n",
    "k = int(input(\"Insert k: \"))\n",
    "assert len(query_2) > 0, \"The query is empty!!\"\n",
    "assert isinstance(k, int), \"k should be an integer!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query_2)\n",
    "print(\"Query:\", query_2)\n",
    "print('k:', k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k, inverted_index, inverted_index_tfidf, inverted_doc, vocabulary)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "                props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SECOND TEST\n",
    "Using 7 words of a description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taking in input the query\n",
    "query_2 = input(\"Insert the query: \")\n",
    "k = int(input(\"Insert k: \"))\n",
    "assert len(query_2) > 0, \"The query is empty!!\"\n",
    "assert isinstance(k, int), \"k should be an integer!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query_2)\n",
    "print(\"Query:\", query_2)\n",
    "print('k:', k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k, inverted_index, inverted_index_tfidf, inverted_doc, vocabulary)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "                props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Define a new Score!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Algorithmic question"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write an algorithm that computes the acceptable solution with the longest possible duration.\n",
    "\n",
    "\n",
    "**MyAlg**\n",
    "\n",
    "```\n",
    "seq = the sequence of request\n",
    "query = the list of requests\n",
    "query_index = empty list\n",
    "\n",
    "for time in query:\n",
    "    query_index.append(seq.index(time))\n",
    "```\n",
    "we write the position of each element of the query in the sequence\n",
    "\n",
    "```\n",
    "new_query=[0 for i in seq]\n",
    "\n",
    "for i in query_index:\n",
    "    new_query[i] = seq[i]\n",
    "\n",
    "new vector with length equal to the length of the sequence, where the elements of the query take position according to query_index, and the other values are 0\n",
    "max_sum_nonadjacent_element(new_query)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Max sum non-adjacent element(A)**\n",
    "\n",
    "```\n",
    "incl_sum = A[0]\n",
    "excl_sum = 0\n",
    "\n",
    "for i = 1 to length(A):\n",
    "    max_sum = max(incl_sum, excl_sum)\n",
    "    incl_sum = excl_sum + A[i]\n",
    "    excl_sum = max_sum\n",
    "\n",
    "max_sum = max(incl_sum, excl_sum)\n",
    "\n",
    "return max_sum\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implement a program that given in input an instance in the form given above, gives the optimal solution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def MyAlg(seq, query):\n",
    "\n",
    "    query_index=[]\n",
    "    seq1=seq.copy()\n",
    "\n",
    "    for time in query:\n",
    "        try:\n",
    "            query_index.append(seq.index(time))\n",
    "            seq[seq.index(time)]=0\n",
    "        except:\n",
    "            print('not valid query')\n",
    "            return\n",
    "\n",
    "    new_query=[0 for i in seq]\n",
    "\n",
    "    for i in query_index:\n",
    "        new_query[i] = seq1[i]\n",
    "\n",
    "    incl_sum = new_query[0]\n",
    "    excl_sum = 0\n",
    "    ind1 = [0]\n",
    "    ind2 = []\n",
    "    indm = ind1[:]\n",
    "    max_sum = incl_sum\n",
    "\n",
    "    for i in range(1, len(new_query)):\n",
    "        incl_sum = excl_sum + new_query[i]\n",
    "        ind2.append(i)\n",
    "        excl_sum = max_sum\n",
    "        ind1 = indm[:]\n",
    "        if incl_sum > excl_sum:\n",
    "            max_sum = incl_sum\n",
    "            indm = ind2[:]\n",
    "            ind2 = ind1 [:]\n",
    "        else:\n",
    "            max_sum = excl_sum\n",
    "            indm = ind1[:]\n",
    "            ind2 = ind1[:]\n",
    "\n",
    "    query_opt = []\n",
    "\n",
    "    for i in indm:\n",
    "        query_opt.append(new_query[i])\n",
    "\n",
    "    print(f\"The optimal solution is: {query_opt}\")\n",
    "    print(f\"The duration is: {max_sum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq=[30, 40, 25, 50, 30, 20]\n",
    "query=[30, 40, 25, 30]\n",
    "MyAlg(seq, query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We added a try/except to avoid an overlap of appointments as shown in the following example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seq = [30, 40, 25, 50, 30, 20]\n",
    "query = [30, 40, 25, 50, 30, 20, 20]\n",
    "MyAlg(seq,query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}