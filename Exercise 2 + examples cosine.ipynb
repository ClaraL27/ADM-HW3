{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mining(string):\n",
    "    # gather all the stopwords\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    # tokenization\n",
    "    tokens = nltk.word_tokenize(string.lower())\n",
    "    # remove punctuations and numbers and then word stemming\n",
    "    res_tok = [PorterStemmer().stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return res_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab():\n",
    "    vocabulary = dict()\n",
    "    for i in tqdm(range(1, 384)):\n",
    "        path = f'pages_tsv/pages_tsv/page_{i}/'\n",
    "        for file in os.listdir(path):\n",
    "            tsv_file = open(path+file, 'r', encoding='utf-8')\n",
    "            anime = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "            descr = anime.__next__()['animeDescription']\n",
    "\n",
    "            for word in text_mining(descr):\n",
    "                if word not in vocabulary.keys():\n",
    "                    vocabulary[word] = len(vocabulary)\n",
    "\n",
    "    file_voc = open(\"vocabulary.json\", \"w\", encoding='utf-8')\n",
    "    json.dump(vocabulary, file_voc, ensure_ascii=False)\n",
    "    file_voc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertedIndex():\n",
    "\n",
    "    inverted_index = dict()\n",
    "\n",
    "    voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "    vocabulary = json.load(voc_json)\n",
    "\n",
    "    # creating an empty inverted_index dictionary\n",
    "    for word in vocabulary:\n",
    "        inverted_index[vocabulary[word]] = []\n",
    "\n",
    "    for i in tqdm(range(1, 384)):\n",
    "        path = f'pages_tsv/pages_tsv/page_{i}/'\n",
    "\n",
    "        for file in os.listdir(path):\n",
    "            tsv_file = open(path+file, 'r', encoding='utf-8')\n",
    "            document_id = 'document_' + (''.join(re.findall(r'\\d+', file)))\n",
    "            anime = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "            descr = anime.__next__()['animeDescription']\n",
    "\n",
    "            for word in text_mining(descr):\n",
    "                if document_id not in inverted_index[vocabulary[word]]:\n",
    "                    inverted_index[vocabulary[word]].append(document_id)\n",
    "\n",
    "    file_inv_ind = open(\"inverted_index.json\", \"w\", encoding='utf-8')\n",
    "    json.dump(inverted_index, file_inv_ind, ensure_ascii=False)\n",
    "    file_inv_ind.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 383/383 [00:41<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "create_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 383/383 [00:43<00:00,  8.86it/s]\n"
     ]
    }
   ],
   "source": [
    "invertedIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the vocabulary\n",
    "voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "vocabulary = json.load(voc_json)\n",
    "voc_json.close()\n",
    "\n",
    "# opening the inverted_index\n",
    "inv_ind_json = open('inverted_index.json', 'r', encoding='utf-8')\n",
    "inverted_index = json.load(inv_ind_json)\n",
    "inv_ind_json.close()\n",
    "\n",
    "# opening the anime_links\n",
    "list_url_txt = open('anime_links.txt', 'r', encoding='utf-8')\n",
    "list_url = list_url_txt.read().splitlines()\n",
    "list_url_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saiyan race\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "assert len(query) > 0, \"The query is empty!!\"\n",
    "# stemming the query\n",
    "query_stemmed = text_mining(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index query dictionary\n",
    "query_dict = dict()\n",
    "for word in query_stemmed:\n",
    "    if word in vocabulary.keys():\n",
    "        query_dict[vocabulary[word]] = inverted_index[str(vocabulary[word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of documents found with the query = {'document_1469', 'document_1035', 'document_365', 'document_401'}\n"
     ]
    }
   ],
   "source": [
    "# saving the inverted_index of the query\n",
    "query_index = list(query_dict.keys())\n",
    "\n",
    "\n",
    "# searching for the documents requested from the query\n",
    "doc_list = set(query_dict[query_index[0]])\n",
    "for query_word in query_index[1:]:\n",
    "    doc_list.intersection_update(query_dict[query_word])\n",
    "\n",
    "print(\"List of documents found with the query =\", doc_list)\n",
    "\n",
    "# creating a pandas dataframe for the final result\n",
    "doc_df = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\"])\n",
    "for doc in doc_list:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96 th {\n",
       "          text-align: center;\n",
       "    }#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col0,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col1,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col2,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col0,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col1,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col2,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col0,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col1,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col2,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col0,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col1,#T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col2{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >animeTitle</th>        <th class=\"col_heading level0 col1\" >animeDescription</th>        <th class=\"col_heading level0 col2\" >Url</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96level0_row0\" class=\"row_heading level0 row0\" >document_1469</th>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col0\" class=\"data row0 col0\" >Dragon Ball Z Special 1: Tatta Hitori no Saishuu Kessen</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col1\" class=\"data row0 col1\" >Bardock, Son Goku's father, is a low-ranking Saiyan soldier who was given the power to see into the future by the last remaining alien on a planet he just destroyed. He witnesses the destruction of his race and must now do his best to stop Frieza's impending massacre.\n",
       "\n",
       "\n",
       "(Source: ANN)</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row0_col2\" class=\"data row0 col2\" ><a href=\"https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen\">https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96level0_row1\" class=\"row_heading level0 row1\" >document_1035</th>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col0\" class=\"data row1 col0\" >Dragon Ball Kai</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col1\" class=\"data row1 col1\" >Five years after the events of Dragon Ball, martial arts expert Gokuu is now a grown man married to his wife Chi-Chi, with a four-year old son named Gohan. While attending a reunion on Turtle Island with his old friends Master Roshi, Krillin, Bulma and others, the festivities are interrupted when a humanoid alien named Raditz not only reveals the truth behind Gokuu's past, but kidnaps Gohan as well.\n",
       "\n",
       "\n",
       "With Raditz displaying power beyond anything Gokuu has seen before, he is forced to team up with his old nemesis, Piccolo, in order to rescue his son. But when Gokuu and Piccolo reveal the secret of the seven mystical wish-granting Dragon Balls to Raditz, he informs the duo that there is more of his race, the Saiyans, and they won’t pass up an opportunity to seize the power of the Dragon Balls for themselves.\n",
       "\n",
       "\n",
       "These events begin the saga of Dragon Ball Kai, a story that finds Gokuu and his friends and family constantly defending the galaxy from increasingly more powerful threats. Bizarre, comical, heartwarming and threatening characters come together in a series of battles that push the powers and abilities of Gokuu and his friends beyond anything they have ever experienced.</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row1_col2\" class=\"data row1 col2\" ><a href=\"https://myanimelist.net/anime/6033/Dragon_Ball_Kai\">https://myanimelist.net/anime/6033/Dragon_Ball_Kai</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96level0_row2\" class=\"row_heading level0 row2\" >document_365</th>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col0\" class=\"data row2 col0\" >Dragon Ball Z</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col1\" class=\"data row2 col1\" >Five years after winning the World Martial Arts tournament, Gokuu is now living a peaceful life with his wife and son. This changes, however, with the arrival of a mysterious enemy named Raditz who presents himself as Gokuu's long-lost brother. He reveals that Gokuu is a warrior from the once powerful but now virtually extinct Saiyan race, whose homeworld was completely annihilated. When he was sent to Earth as a baby, Gokuu's sole purpose was to conquer and destroy the planet; but after suffering amnesia from a head injury, his violent and savage nature changed, and instead was raised as a kind and well-mannered boy, now fighting to protect others.\n",
       "\n",
       "\n",
       "With his failed attempt at forcibly recruiting Gokuu as an ally, Raditz warns Gokuu's friends of a new threat that's rapidly approaching Earth—one that could plunge Earth into an intergalactic conflict and cause the heavens themselves to shake. A war will be fought over the seven mystical dragon balls, and only the strongest will survive in Dragon Ball Z.\n",
       "\n",
       "\n",
       "[Written by MAL Rewrite]</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row2_col2\" class=\"data row2 col2\" ><a href=\"https://myanimelist.net/anime/813/Dragon_Ball_Z\">https://myanimelist.net/anime/813/Dragon_Ball_Z</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96level0_row3\" class=\"row_heading level0 row3\" >document_401</th>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col0\" class=\"data row3 col0\" >Dragon Ball Super: Broly</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col1\" class=\"data row3 col1\" >Forty-one years ago on Planet Vegeta, home of the infamous Saiyan warrior race, King Vegeta noticed a baby named Broly whose latent power exceeded that of his own son. Believing that Broly's power would one day surpass that of his child, Vegeta, the king sends Broly to the desolate planet Vampa. Broly's father Paragus follows after him, intent on rescuing his son. However, his ship gets damaged, causing the two to spend years trapped on the barren world, unaware of the salvation that would one day come from an unlikely ally.\n",
       "\n",
       "\n",
       "Years later on Earth, Gokuu Son and Prince Vegeta—believed to be the last survivors of the Saiyan race—are busy training on a remote island. But their sparring is interrupted when the appearance of their old enemy Frieza drives them to search for the last of the wish-granting Dragon Balls on a frozen continent. Once there, Frieza shows off his new allies: Paragus and the now extremely powerful Broly. A legendary battle that shakes the foundation of the world ensues as Gokuu and Vegeta face off against Broly, a warrior without equal whose rage is just waiting to be unleashed.\n",
       "\n",
       "\n",
       "[Written by MAL Rewrite]</td>\n",
       "                        <td id=\"T_92dcfae3_4321_11ec_a6a5_3c2c30bb8f96row3_col2\" class=\"data row3 col2\" ><a href=\"https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly\">https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly</a></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x212fb783670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_d = dict(selector=\"th\",\n",
    "             props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_d]).format({'Url': make_clickable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two dictionaries:\n",
    "- inverted_term such that for each word we have the list of documents in which it is contained in, and the relative tfIdf score.\n",
    "- inverte_doc such that for each document we have the sum of the squares of the tfidf, we will use this dictonary in the execute query.\n",
    "\n",
    "We compute the tf-idf as $tf*idf$:\n",
    "- $tf=\\frac{n_i}{|d|}$, n is the number of occurences of the i-th word in the document and |d| is the number of words in the document\n",
    "- $idf=log_{10}\\left(\\frac{N}{n_d}\\right)$, N is the total number of documents and $n_d$ is the number of documents contaning the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted():\n",
    "    \n",
    "    inverted_term = dict()\n",
    "    inverted_doc = dict()\n",
    "    \n",
    "    #opening the vocabulary\n",
    "    voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "    vocabulary = json.load(voc_json)\n",
    "    \n",
    "    # opening the inverted_index\n",
    "    inv_ind_json = open('inverted_index.json', 'r', encoding='utf-8')\n",
    "    inverted_index = json.load(inv_ind_json)\n",
    "    inv_ind_json.close()\n",
    "    \n",
    "\n",
    "    # creating an empty inverted_index dictionary\n",
    "    for word in vocabulary:\n",
    "        inverted_term[vocabulary[word]] = []\n",
    "\n",
    "    for i in tqdm(range(1, 384)):\n",
    "        path = f'pages_tsv/pages_tsv/page_{i}/'\n",
    "\n",
    "        for file in os.listdir(path):\n",
    "            tsv_file = open(path+file, 'r', encoding='utf-8')\n",
    "            document_id = 'document_' + (''.join(re.findall(r'\\d+', file)))\n",
    "            anime = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "            descr = anime.__next__()['animeDescription']\n",
    "            descr = text_mining(descr)\n",
    "\n",
    "            for word in descr:\n",
    "                tf = descr.count(word) / len(descr)\n",
    "                idf = np.log10(19128/len(inverted_index[str(vocabulary[word])]))\n",
    "                tfidf = tf * idf\n",
    "                if (document_id, tfidf) not in inverted_term[vocabulary[word]]:\n",
    "                    inverted_term[vocabulary[word]].append((document_id, tfidf))\n",
    "                if document_id not in inverted_doc:\n",
    "                    inverted_doc[document_id] = np.square(tfidf)\n",
    "                else:\n",
    "                    inverted_doc[document_id] = inverted_doc[document_id] + np.square(tfidf)\n",
    "                        \n",
    "\n",
    "    file_inv_term = open(\"inverted_term.json\", \"w\", encoding='utf-8')\n",
    "    json.dump(inverted_term, file_inv_term, ensure_ascii=False)\n",
    "    file_inv_term.close()\n",
    "    \n",
    "    file_inv_doc = open(\"inverted_doc.json\", \"w\", encoding='utf-8')\n",
    "    json.dump(inverted_doc, file_inv_doc, ensure_ascii=False)\n",
    "    file_inv_doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 383/383 [01:05<00:00,  5.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# creates the inverted_term and inverted_doc dictionaries and stores them in a json file\n",
    "inverted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a query we get the set of documents containing all the words in the query and sort them according to their similairty to the query\n",
    "\n",
    "- First we consider only the documents that contain all the words in the query.\n",
    "\n",
    "- We create a dictonary called numerator such that for each document we have the tf-idf sum of the words in the query in reference to the document.\n",
    "\n",
    "- We compute the cosine similarity for each document as $ cos(\\theta) = \\frac{(\\vec{q} \\cdot \\vec{d})}{(|{\\vec{q}}| \\cdot |{\\vec{d}}|)}$ where:\n",
    "<p> $(\\vec{q} \\cdot \\vec{d})$ is the intersection of the document and the query vectors: we used the numerator dictonary argument for each document as intersection;<p>\n",
    "<p> $|{\\vec{q}}| \\cdot |{\\vec{d}}|$  are the norms of the document and query vectors . We compute $|{\\vec{q}}|$ as the square root of the length of the query (because the query vector has only components equal to 1 corresponding to the query words). We compute $|{\\vec{d}}|$ as the square root of the sum of the squares of the tf-idf of all words in the document (so we use the inverted_doc dictonary to compute the document norm)<p>\n",
    "\n",
    "- Then we create the result dictonary to store for each document the corresponding cosine similarity to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the vocabulary\n",
    "voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "vocabulary = json.load(voc_json)\n",
    "voc_json.close()\n",
    "\n",
    "# opening the inverted_index\n",
    "inv_ind_json = open('inverted_index.json', 'r', encoding='utf-8')\n",
    "inverted_index = json.load(inv_ind_json)\n",
    "inv_ind_json.close()\n",
    "\n",
    "#opening the inverted_term\n",
    "inv_term_json = open('inverted_term.json', 'r', encoding='utf-8')\n",
    "inverted_term = json.load(inv_term_json)\n",
    "inv_term_json.close()\n",
    "\n",
    "#opening the inverted_doc\n",
    "inv_doc_json = open('inverted_doc.json', 'r', encoding='utf-8')\n",
    "inverted_doc = json.load(inv_doc_json)\n",
    "inv_doc_json.close()\n",
    "\n",
    "\n",
    "# opening the anime_links\n",
    "list_url_txt = open('anime_links.txt', 'r', encoding='utf-8')\n",
    "list_url = list_url_txt.read().splitlines()\n",
    "list_url_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index query dictionary\n",
    "def create_index_query(query):\n",
    "    \n",
    "    #opening the vocabulary\n",
    "    voc_json = open('vocabulary.json', 'r', encoding='utf-8')\n",
    "    vocabulary = json.load(voc_json)\n",
    "    voc_json.close()\n",
    "    \n",
    "    query_dict_2 = dict()\n",
    "    for word in query:\n",
    "        if word in vocabulary.keys():\n",
    "            query_dict_2[vocabulary[word]] = inverted_index[str(vocabulary[word])]\n",
    "    return query_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similarity(query):\n",
    "    \n",
    "    # opening the inverted_term\n",
    "    inv_term_json = open('inverted_term.json', 'r', encoding='utf-8')\n",
    "    inverted_term = json.load(inv_term_json)\n",
    "    inv_term_json.close()\n",
    "    \n",
    "    # opening the inverted_doc\n",
    "    inv_doc_json = open('inverted_doc.json', 'r', encoding='utf-8')\n",
    "    inverted_doc = json.load(inv_doc_json)\n",
    "    inv_doc_json.close()\n",
    "    \n",
    "    # saving the inverted_index of the query\n",
    "    query_dict_2 = create_index_query(query)\n",
    "    query_index_2 = list(query_dict_2.keys())\n",
    "    \n",
    "    # searching for the documents requested from the query\n",
    "    doc_list_2 = set(query_dict_2[query_index_2[0]])\n",
    "\n",
    "    for query_word in query_index_2[1:]:\n",
    "        doc_list_2.intersection_update(query_dict_2[query_word])\n",
    "        \n",
    "    # create the heap list in order to take the first k documents     \n",
    "    heap = list()\n",
    "    heapq.heapify(heap)\n",
    "    result, numerator = dict(), dict()\n",
    "    \n",
    "    #creating the numerator dictonary\n",
    "    for word in query:\n",
    "        for elem in inverted_term[str(vocabulary[word])]:\n",
    "            if elem[0] in doc_list_2:\n",
    "                if elem[0] not in numerator:\n",
    "                    numerator[elem[0]] = elem[1]\n",
    "                else:\n",
    "                    numerator[elem[0]] = numerator[elem[0]] + elem[1]\n",
    "    \n",
    "    for document in doc_list_2:\n",
    "        cos_sim = numerator[document]/(np.sqrt(inverted_doc[document]) * np.sqrt(len(query_stemmed_2)))\n",
    "        result[document] = cos_sim\n",
    "        heapq.heappush(heap, cos_sim)\n",
    "        \n",
    "    return result, heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_documents(query, k):\n",
    "    # we are taking the first k similar documents to the query using heapq\n",
    "    result, heap = search_similarity(query)\n",
    "    heap_k = heapq.nlargest(k, heap)\n",
    "    final_doc = dict()\n",
    "    for i in range(len(heap_k)):\n",
    "        pos = list(result.values()).index(heap_k[i])\n",
    "        final_doc[list(result)[pos]] = result[list(result)[pos]]\n",
    "    return final_doc, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert the query: \n",
      "saiyan race\n",
      "insert k: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"insert the query: \")\n",
    "query = input()\n",
    "print(\"insert k: \")\n",
    "k = int(input())\n",
    "assert len(query) > 0, \"The query is empty!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ffa441b1_4323_11ec_a949_3c2c30bb8f96 th {\n",
       "          text-align: center;\n",
       "    }#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col0,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col1,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col2,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col3,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col0,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col1,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col2,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col3,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col0,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col1,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col2,#T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col3{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >animeTitle</th>        <th class=\"col_heading level0 col1\" >animeDescription</th>        <th class=\"col_heading level0 col2\" >Url</th>        <th class=\"col_heading level0 col3\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96level0_row0\" class=\"row_heading level0 row0\" >document_1469</th>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col0\" class=\"data row0 col0\" >Dragon Ball Z Special 1: Tatta Hitori no Saishuu Kessen</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col1\" class=\"data row0 col1\" >Bardock, Son Goku's father, is a low-ranking Saiyan soldier who was given the power to see into the future by the last remaining alien on a planet he just destroyed. He witnesses the destruction of his race and must now do his best to stop Frieza's impending massacre.\n",
       "\n",
       "\n",
       "(Source: ANN)</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col2\" class=\"data row0 col2\" ><a href=\"https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen\">https://myanimelist.net/anime/986/Dragon_Ball_Z_Special_1__Tatta_Hitori_no_Saishuu_Kessen</a></td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row0_col3\" class=\"data row0 col3\" >0.320894</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96level0_row1\" class=\"row_heading level0 row1\" >document_401</th>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col0\" class=\"data row1 col0\" >Dragon Ball Super: Broly</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col1\" class=\"data row1 col1\" >Forty-one years ago on Planet Vegeta, home of the infamous Saiyan warrior race, King Vegeta noticed a baby named Broly whose latent power exceeded that of his own son. Believing that Broly's power would one day surpass that of his child, Vegeta, the king sends Broly to the desolate planet Vampa. Broly's father Paragus follows after him, intent on rescuing his son. However, his ship gets damaged, causing the two to spend years trapped on the barren world, unaware of the salvation that would one day come from an unlikely ally.\n",
       "\n",
       "\n",
       "Years later on Earth, Gokuu Son and Prince Vegeta—believed to be the last survivors of the Saiyan race—are busy training on a remote island. But their sparring is interrupted when the appearance of their old enemy Frieza drives them to search for the last of the wish-granting Dragon Balls on a frozen continent. Once there, Frieza shows off his new allies: Paragus and the now extremely powerful Broly. A legendary battle that shakes the foundation of the world ensues as Gokuu and Vegeta face off against Broly, a warrior without equal whose rage is just waiting to be unleashed.\n",
       "\n",
       "\n",
       "[Written by MAL Rewrite]</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col2\" class=\"data row1 col2\" ><a href=\"https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly\">https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly</a></td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row1_col3\" class=\"data row1 col3\" >0.085567</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96level0_row2\" class=\"row_heading level0 row2\" >document_365</th>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col0\" class=\"data row2 col0\" >Dragon Ball Z</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col1\" class=\"data row2 col1\" >Five years after winning the World Martial Arts tournament, Gokuu is now living a peaceful life with his wife and son. This changes, however, with the arrival of a mysterious enemy named Raditz who presents himself as Gokuu's long-lost brother. He reveals that Gokuu is a warrior from the once powerful but now virtually extinct Saiyan race, whose homeworld was completely annihilated. When he was sent to Earth as a baby, Gokuu's sole purpose was to conquer and destroy the planet; but after suffering amnesia from a head injury, his violent and savage nature changed, and instead was raised as a kind and well-mannered boy, now fighting to protect others.\n",
       "\n",
       "\n",
       "With his failed attempt at forcibly recruiting Gokuu as an ally, Raditz warns Gokuu's friends of a new threat that's rapidly approaching Earth—one that could plunge Earth into an intergalactic conflict and cause the heavens themselves to shake. A war will be fought over the seven mystical dragon balls, and only the strongest will survive in Dragon Ball Z.\n",
       "\n",
       "\n",
       "[Written by MAL Rewrite]</td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col2\" class=\"data row2 col2\" ><a href=\"https://myanimelist.net/anime/813/Dragon_Ball_Z\">https://myanimelist.net/anime/813/Dragon_Ball_Z</a></td>\n",
       "                        <td id=\"T_ffa441b1_4323_11ec_a949_3c2c30bb8f96row2_col3\" class=\"data row2 col3\" >0.067677</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x212f8182610>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "             props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we were computing the cosine similarity in the right way, we did some tests considering the description of some documents as a query.\n",
    "<p>In the first test we used as a query the description of document 401 and the cosine similarity is 0.65, it is a high similarity value, but the value should have been around 1 (having used the document description itself). This does not happen because the description of the 401 document is very long (the number of words is high) and therefore the cosine similarity is less reliable. <p>\n",
    "<p>In the second test instead we used the description of document 203 which has only 7 words and in this case the cosine similarity is 0.96.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert the query: \n",
      "Forty-one years ago on Planet Vegeta, home of the infamous Saiyan warrior race, King Vegeta noticed a baby named Broly whose latent power exceeded that of his own son. Believing that Broly's power would one day surpass that of his child, Vegeta, the king sends Broly to the desolate planet Vampa. Broly's father Paragus follows after him, intent on rescuing his son. However, his ship gets damaged, causing the two to spend years trapped on the barren world, unaware of the salvation that would one day come from an unlikely ally. Years later on Earth, Gokuu Son and Prince Vegeta—believed to be the last survivors of the Saiyan race—are busy training on a remote island. But their sparring is interrupted when the appearance of their old enemy Frieza drives them to search for the last of the wish-granting Dragon Balls on a frozen continent. Once there, Frieza shows off his new allies: Paragus and the now extremely powerful Broly. A legendary battle that shakes the foundation of the world ensues as Gokuu and Vegeta face off against Broly, a warrior without equal whose rage is just waiting to be unleashed. [Written by MAL Rewrite]\n",
      "insert k: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"insert the query: \")\n",
    "query = input()\n",
    "print(\"insert k: \")\n",
    "k = int(input())\n",
    "assert len(query) > 0, \"The query is empty!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_71a417ad_4324_11ec_a64f_3c2c30bb8f96 th {\n",
       "          text-align: center;\n",
       "    }#T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col0,#T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col1,#T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col2,#T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col3{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >animeTitle</th>        <th class=\"col_heading level0 col1\" >animeDescription</th>        <th class=\"col_heading level0 col2\" >Url</th>        <th class=\"col_heading level0 col3\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96level0_row0\" class=\"row_heading level0 row0\" >document_401</th>\n",
       "                        <td id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col0\" class=\"data row0 col0\" >Dragon Ball Super: Broly</td>\n",
       "                        <td id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col1\" class=\"data row0 col1\" >Forty-one years ago on Planet Vegeta, home of the infamous Saiyan warrior race, King Vegeta noticed a baby named Broly whose latent power exceeded that of his own son. Believing that Broly's power would one day surpass that of his child, Vegeta, the king sends Broly to the desolate planet Vampa. Broly's father Paragus follows after him, intent on rescuing his son. However, his ship gets damaged, causing the two to spend years trapped on the barren world, unaware of the salvation that would one day come from an unlikely ally.\n",
       "\n",
       "\n",
       "Years later on Earth, Gokuu Son and Prince Vegeta—believed to be the last survivors of the Saiyan race—are busy training on a remote island. But their sparring is interrupted when the appearance of their old enemy Frieza drives them to search for the last of the wish-granting Dragon Balls on a frozen continent. Once there, Frieza shows off his new allies: Paragus and the now extremely powerful Broly. A legendary battle that shakes the foundation of the world ensues as Gokuu and Vegeta face off against Broly, a warrior without equal whose rage is just waiting to be unleashed.\n",
       "\n",
       "\n",
       "[Written by MAL Rewrite]</td>\n",
       "                        <td id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col2\" class=\"data row0 col2\" ><a href=\"https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly\">https://myanimelist.net/anime/36946/Dragon_Ball_Super__Broly</a></td>\n",
       "                        <td id=\"T_71a417ad_4324_11ec_a64f_3c2c30bb8f96row0_col3\" class=\"data row0 col3\" >0.655309</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x212fb783c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "             props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert the query: \n",
      "Two special episodes bundled in the fourth and fifth volume of the Blu-ray/DVD.\n",
      "insert k: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"insert the query: \")\n",
    "query = input()\n",
    "print(\"insert k: \")\n",
    "k = int(input())\n",
    "assert len(query) > 0, \"The query is empty!!\"\n",
    "# stemming the query\n",
    "query_stemmed_2 = text_mining(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pandas dataframe for the final result\n",
    "doc_df_2 = pd.DataFrame(columns=[\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"])\n",
    "final_doc, result = top_k_documents(query_stemmed_2, k)\n",
    "for doc in final_doc:\n",
    "    i = int(''.join(re.findall(r'\\d+', doc)))\n",
    "    doc_page = (i-1)//50 + 1\n",
    "    path = f'pages_tsv/pages_tsv/page_{doc_page}/anime_{i}.tsv'\n",
    "    tsv_file = open(path, 'r', encoding='utf-8')\n",
    "    anime_tsv = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    anime = anime_tsv.__next__()\n",
    "    doc_df_2.loc[doc, [\"animeTitle\", \"animeDescription\", \"Url\", \"Similarity\"]] = [anime[\"animeTitle\"], anime[\"animeDescription\"], list_url[i-1], result[doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ec642215_4324_11ec_afac_3c2c30bb8f96 th {\n",
       "          text-align: center;\n",
       "    }#T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col0,#T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col1,#T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col2,#T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col3{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >animeTitle</th>        <th class=\"col_heading level0 col1\" >animeDescription</th>        <th class=\"col_heading level0 col2\" >Url</th>        <th class=\"col_heading level0 col3\" >Similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96level0_row0\" class=\"row_heading level0 row0\" >document_203</th>\n",
       "                        <td id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col0\" class=\"data row0 col0\" >Natsume Yuujinchou Go Specials</td>\n",
       "                        <td id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col1\" class=\"data row0 col1\" >Two special episodes bundled in the fourth and fifth volume of the Blu-ray/DVD.</td>\n",
       "                        <td id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col2\" class=\"data row0 col2\" ><a href=\"https://myanimelist.net/anime/34534/Natsume_Yuujinchou_Go_Specials\">https://myanimelist.net/anime/34534/Natsume_Yuujinchou_Go_Specials</a></td>\n",
       "                        <td id=\"T_ec642215_4324_11ec_afac_3c2c30bb8f96row0_col3\" class=\"data row0 col3\" >0.961133</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x212f81822b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(selector=\"th\",\n",
    "             props=[('text-align', 'center')])\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "doc_df_2.style.set_properties(**{'text-align':'center'}).set_table_styles([doc_dict]).format({'Url': make_clickable})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
